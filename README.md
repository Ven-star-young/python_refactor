# 神经网络识别装甲板

## 数据集参数

相关参数：
```
图像格式: BMP
图像尺寸: 1240x1624
通道数: 1(灰度图)
数据类型: uint8
```

## 实现

由于图像仅有灰度通道，无法区别红蓝，所以神经网络仅识别装甲板的位置和数字，后续通过灯条的位置结合rgb图像来进行颜色判断。

## 选择模型

YOLOv8n-pose

## 模型输入与输出

### 模型输入

```
image: 要转为3通道的灰度图像(1240x1624x3)

<class-index> <x_center> <y_center> <width> <height> <px1> <py1> <px2> <py2> <px3> <py3> <px4> <py4>
```

### 模型输出

```
class_id: 装甲板0-8.
KeyPoints: 装甲板灯条的四个顶点坐标(x1,y1,x2,y2,x3,y3,x4,y4)
```

## 目前的问题（2026.2.1）

- 模型的输出可能得调整为:与装甲板相关的所有灯条，意味着标注文件需要所有相关灯条的坐标，而不是仅仅装甲板的四个顶点坐标。
- 目前标注文件中仅有装甲板的四个顶点坐标，需要重新标注数据集。

### 现在的难点&需要考虑的事

- 如何确定哪些灯条属于同一个装甲板？->先去看看原来传统方法是如何实现的。
- 传统算法的灯条识别不稳定，导致标注文件难生成。
- 将原来的双层结构改为单层结构，能够节省多少时间以及提升多少准确率？


- but:图像数据是灰度图像，无法用颜色来区分灯条进行筛选。

## 尝试新的标注

使用一辆车上的所有灯条关键点，最多有四个灯条、8个关键点。